{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import Common_Functions as cmn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figuring out which Regressions to apply to our Datasets using a MSE Test on our Training Data\n",
    "\n",
    "Following Notebooks 1.0 and 1.1, we decided to continue the evaluation without the columns that include strings, like, for example, MSZoning or Street, as the label encoder didn't give significantly different results in our model compared to when not taking them into account. We therefore exported the \"new\" trianing and test data, without strings into new CSVs called stringless_train.csv and stringless_test.csv to be read by the function in the common_functions.py file for further use. This way, we eliminate the need to reread the original csvs and remove all NaN values and string values.\n",
    "\n",
    "### Hypothesis 2\n",
    "We think that the two best regressors will be the random forest and the machine learning model MLPRegressor, as ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_data = cmn.get_stringless_training_data()\n",
    "testing_data = cmn.get_stringless_testing_data()\n",
    "display(training_data.head(), testing_data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the training data has one additional column, containing the sale price of the house with its given parameters, we split the dataframe into the X_train and y_train dataframes to continue with the calculations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = training_data.iloc[:, :-1]\n",
    "y_train = training_data.iloc[:, -1:]\n",
    "display(X_train.shape, X_train.head(), y_train.shape, y_train.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = testing_data\n",
    "y_test = [] # y_test does not exist in the testing data like above, so we are creating an empty list as a placeholder.\n",
    "display(X_test.shape, X_test.head(), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scoring various Regression Models to verify which we will be using going forward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train)\n",
    "y = np.log1p(y_train)\n",
    "cross_validation = 10\n",
    "scores_map = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Random Forest Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "\n",
    "scores = cross_val_score(forest, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['Random Forest'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Gradient Boosting Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(alpha=0.9,learning_rate=0.05, max_depth=2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, random_state=1)\n",
    "\n",
    "scores = cross_val_score(gbr, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['Gradient Boosting Regressor'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Decision Tree Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "scores = cross_val_score(decision_tree, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['Decision Tree Regressor'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Support Vector Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "\n",
    "scores = cross_val_score(svr, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['Support Vector Regression'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### K Nearest Neighbors Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=7)\n",
    "\n",
    "scores = cross_val_score(knn, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['K Nearest Neighbors Regressor'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(linear_regression, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['Linear Regression'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### XGBoost Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgboost = XGBRegressor(n_estimators=1000)\n",
    "\n",
    "scores = cross_val_score(xgboost, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['XGBoost Regressor'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Multilayer Perceptron Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp_regression = MLPRegressor(max_iter=10000)\n",
    "\n",
    "scores = cross_val_score(mlp_regression, x_scaled, np.ravel(y.astype(float)), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['MLP Regressor'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "#\n",
    "# clf = MLPClassifier(max_iter=10000)\n",
    "# #print(np.ravel(y))\n",
    "# #clf.fit(x_scaled, np.ravel(y_train))\n",
    "# scores = cross_val_score(clf, x_scaled, np.ravel(y.astype(float)), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "# print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "#\n",
    "# scores_map['MLPClassifier'] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5.2))\n",
    "scores_map = pd.DataFrame(scores_map)\n",
    "sns.boxplot(data=scores_map)\n",
    "plt.ylim(-.05, -.01)\n",
    "plt.ylabel(r\"Regression Error\")\n",
    "#plt.title(\"Mean-Squared Error of all Regressions\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see above our hypthesis was not correct. In fact, the machine learning model MLP Regressor didnt even make it in the top half of all our models, and we will therefore not continue with that model going forward.\n",
    "\n",
    "Instead, Gradient boosting regressor was the best for this dataset, closely followed by the random forest, the linear model, and finally XGB."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

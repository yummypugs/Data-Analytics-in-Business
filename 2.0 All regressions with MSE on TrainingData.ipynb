{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import pandas as pd\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "    MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\nId                                                                          \n1           60         65.0     8450            7            5       2003   \n2           20         80.0     9600            6            8       1976   \n3           60         68.0    11250            7            5       2001   \n4           70         60.0     9550            7            5       1915   \n5           60         84.0    14260            8            5       2000   \n\n    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\nId                                                    ...               \n1           2003       196.0         706           0  ...           0   \n2           1976         0.0         978           0  ...         298   \n3           2002       162.0         486           0  ...           0   \n4           1970         0.0         216           0  ...           0   \n5           2000       350.0         655           0  ...         192   \n\n    OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\nId                                                                          \n1            61              0          0            0         0        0   \n2             0              0          0            0         0        0   \n3            42              0          0            0         0        0   \n4            35            272          0            0         0        0   \n5            84              0          0            0         0        0   \n\n    MoSold  YrSold  SalePrice  \nId                             \n1        2    2008     208500  \n2        5    2007     181500  \n3        9    2008     223500  \n4        2    2006     140000  \n5       12    2008     250000  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 37 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\nId                                                                            \n1461          20         80.0    11622            5            6       1961   \n1462          20         81.0    14267            6            6       1958   \n1463          60         74.0    13830            5            5       1997   \n1464          60         78.0     9978            6            6       1998   \n1465         120         43.0     5005            8            5       1992   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\nId                                                      ...               \n1461          1961         0.0       468.0       144.0  ...       730.0   \n1462          1958       108.0       923.0         0.0  ...       312.0   \n1463          1998         0.0       791.0         0.0  ...       482.0   \n1464          1998        20.0       602.0         0.0  ...       470.0   \n1465          1992         0.0       263.0         0.0  ...       506.0   \n\n      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\nId                                                                     \n1461         140            0              0          0          120   \n1462         393           36              0          0            0   \n1463         212           34              0          0            0   \n1464         360           36              0          0            0   \n1465           0           82              0          0          144   \n\n      PoolArea  MiscVal  MoSold  YrSold  \nId                                       \n1461         0        0       6    2010  \n1462         0    12500       6    2010  \n1463         0        0       3    2010  \n1464         0        0       6    2010  \n1465         0        0       1    2010  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1461</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>11622</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1961</td>\n      <td>1961</td>\n      <td>0.0</td>\n      <td>468.0</td>\n      <td>144.0</td>\n      <td>...</td>\n      <td>730.0</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1462</th>\n      <td>20</td>\n      <td>81.0</td>\n      <td>14267</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1958</td>\n      <td>1958</td>\n      <td>108.0</td>\n      <td>923.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>312.0</td>\n      <td>393</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12500</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1463</th>\n      <td>60</td>\n      <td>74.0</td>\n      <td>13830</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1997</td>\n      <td>1998</td>\n      <td>0.0</td>\n      <td>791.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>482.0</td>\n      <td>212</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1464</th>\n      <td>60</td>\n      <td>78.0</td>\n      <td>9978</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1998</td>\n      <td>1998</td>\n      <td>20.0</td>\n      <td>602.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>470.0</td>\n      <td>360</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1465</th>\n      <td>120</td>\n      <td>43.0</td>\n      <td>5005</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1992</td>\n      <td>1992</td>\n      <td>0.0</td>\n      <td>263.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>506.0</td>\n      <td>0</td>\n      <td>82</td>\n      <td>0</td>\n      <td>0</td>\n      <td>144</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2010</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"house-prices-advanced-regression-techniques/stringless_train.csv\", index_col=\"Id\")\n",
    "testing_data = pd.read_csv(\"house-prices-advanced-regression-techniques/stringless_test.csv\", index_col=\"Id\")\n",
    "display(training_data.head(), testing_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(2919, 37)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0          60         65.0     8450            7            5       2003   \n1          20         80.0     9600            6            8       1976   \n2          60         68.0    11250            7            5       2001   \n3          70         60.0     9550            7            5       1915   \n4          60         84.0    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n0          2003       196.0       706.0         0.0  ...           0   \n1          1976         0.0       978.0         0.0  ...         298   \n2          2002       162.0       486.0         0.0  ...           0   \n3          1970         0.0       216.0         0.0  ...           0   \n4          2000       350.0       655.0         0.0  ...         192   \n\n   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0           61              0          0            0         0        0   \n1            0              0          0            0         0        0   \n2           42              0          0            0         0        0   \n3           35            272          0            0         0        0   \n4           84              0          0            0         0        0   \n\n   MoSold  YrSold  SalePrice  \n0       2    2008   208500.0  \n1       5    2007   181500.0  \n2       9    2008   223500.0  \n3       2    2006   140000.0  \n4      12    2008   250000.0  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>208500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>181500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>223500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>140000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>250000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 37 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = pd.concat((training_data, testing_data)).reset_index(drop=True)\n",
    "display(all_data.shape, all_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "scores_map = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest on Training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "((1460, 37), (1459, 37))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0          60         65.0     8450            7            5       2003   \n1          20         80.0     9600            6            8       1976   \n2          60         68.0    11250            7            5       2001   \n3          70         60.0     9550            7            5       1915   \n4          60         84.0    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n0          2003       196.0       706.0         0.0  ...           0   \n1          1976         0.0       978.0         0.0  ...         298   \n2          2002       162.0       486.0         0.0  ...           0   \n3          1970         0.0       216.0         0.0  ...           0   \n4          2000       350.0       655.0         0.0  ...         192   \n\n   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0           61              0          0            0         0        0   \n1            0              0          0            0         0        0   \n2           42              0          0            0         0        0   \n3           35            272          0            0         0        0   \n4           84              0          0            0         0        0   \n\n   MoSold  YrSold  SalePrice  \n0       2    2008   208500.0  \n1       5    2007   181500.0  \n2       9    2008   223500.0  \n3       2    2006   140000.0  \n4      12    2008   250000.0  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>208500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>181500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>223500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>140000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>250000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 37 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = all_data.iloc[:1460, :]\n",
    "testing_data = all_data.iloc[-1459:, :]\n",
    "display((training_data.shape, testing_data.shape), training_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0          60         65.0     8450            7            5       2003   \n1          20         80.0     9600            6            8       1976   \n2          60         68.0    11250            7            5       2001   \n3          70         60.0     9550            7            5       1915   \n4          60         84.0    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n0          2003       196.0       706.0         0.0  ...       548.0   \n1          1976         0.0       978.0         0.0  ...       460.0   \n2          2002       162.0       486.0         0.0  ...       608.0   \n3          1970         0.0       216.0         0.0  ...       642.0   \n4          2000       350.0       655.0         0.0  ...       836.0   \n\n   WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n0           0           61              0          0            0         0   \n1         298            0              0          0            0         0   \n2           0           42              0          0            0         0   \n3           0           35            272          0            0         0   \n4         192           84              0          0            0         0   \n\n   MiscVal  MoSold  YrSold  \n0        0       2    2008  \n1        0       5    2007  \n2        0       9    2008  \n3        0       2    2006  \n4        0      12    2008  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>548.0</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>460.0</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>608.0</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>642.0</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>836.0</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   SalePrice\n0   208500.0\n1   181500.0\n2   223500.0\n3   140000.0\n4   250000.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>208500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>181500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>223500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>250000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test = training_data.iloc[:,:-1], testing_data.iloc[:,:-1]\n",
    "#X_test\n",
    "y_train, y_test = training_data.iloc[:,-1:], testing_data.iloc[:,-1:]\n",
    "#y_test.drop(['SalePrice'], axis=1, inplace=True)\n",
    "display(X_train.head(), y_train.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_1660\\3799881120.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor()",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on training data: 0.9802235280438041\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([206174.8 , 174991.37, 220210.78, ..., 261746.53, 140883.75,\n       149790.  ])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model score on training data:\", forest.score(X_train, y_train))\n",
    "#print(\"model score on test data:\", forest.score(X_test, y_test)) # we do not need this as we do not yet have any prices to compare the random forest model for the missing data\n",
    "y_predicted = forest.predict(X_train) # This becomes our predicted prices for the missing dataset using forest prediction\n",
    "y_predicted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train)\n",
    "y = np.log1p(y_train)\n",
    "cross_validation = 10\n",
    "\n",
    "scores_map = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.02104015262352621 (+/- 0.005555056462922725)\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestRegressor()\n",
    "\n",
    "scores = cross_val_score(forest, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')  #kfold cv=cross_validation\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['RandomForest'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.01788777753937798 (+/- 0.006261930780067034)\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(alpha=0.9,learning_rate=0.05, max_depth=2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, random_state=1)\n",
    "\n",
    "scores = cross_val_score(gbr, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['GradientBoostingRegressor'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.038642083834822816 (+/- 0.004277286759302694)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "desc_tr = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "scores = cross_val_score(desc_tr, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['DecisionTreeRegressor'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.03071687307318508 (+/- 0.008713164975748637)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "\n",
    "scores = cross_val_score(svr_rbf, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['SVR'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.03532707320275842 (+/- 0.004905416346074496)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=7)\n",
    "\n",
    "scores = cross_val_score(knn, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['KNeighborsRegressor'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.02541931315572456 (+/- 0.014454045568897995)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "l_regression = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(l_regression, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['LinearRegression'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01845298 -0.01315922 -0.01775841 -0.02801882 -0.02386893 -0.0161584\n",
      " -0.02006629 -0.01942832 -0.02267568 -0.02191934]\n",
      "MSE: -0.020150639707389277 (+/- 0.003989857965839384)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=1000)\n",
    "\n",
    "scores = cross_val_score(xgb, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(scores)\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['XGBRegressor'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\.conda\\envs\\HousingProject\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([12.24769912, 12.10901644, 12.31717117, ..., 12.49313327,\n       11.86446927, 11.90159023]),)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [150], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mneural_network\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MLPClassifier\n\u001B[0;32m      3\u001B[0m clf \u001B[38;5;241m=\u001B[39m MLPClassifier(solver\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlbfgs\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m, hidden_layer_sizes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m2\u001B[39m), random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m clf\u001B[38;5;241m.\u001B[39mfit(x_scaled, pd\u001B[38;5;241m.\u001B[39mDataFrame(y))\n",
      "File \u001B[1;32m~\\.conda\\envs\\HousingProject\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:762\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[0;32m    746\u001B[0m     \u001B[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \n\u001B[0;32m    748\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;124;03m        Returns a trained MLP model.\u001B[39;00m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincremental\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\HousingProject\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:394\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._fit\u001B[1;34m(self, X, y, incremental)\u001B[0m\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    388\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhidden_layer_sizes must be > 0, got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m hidden_layer_sizes\n\u001B[0;32m    389\u001B[0m     )\n\u001B[0;32m    390\u001B[0m first_pass \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoefs_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarm_start \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m incremental\n\u001B[0;32m    392\u001B[0m )\n\u001B[1;32m--> 394\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincremental\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfirst_pass\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    396\u001B[0m n_samples, n_features \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    398\u001B[0m \u001B[38;5;66;03m# Ensure y is 2D\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\HousingProject\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1140\u001B[0m, in \u001B[0;36mMLPClassifier._validate_input\u001B[1;34m(self, X, y, incremental, reset)\u001B[0m\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclasses_\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarm_start \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m incremental):\n\u001B[0;32m   1139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label_binarizer \u001B[38;5;241m=\u001B[39m LabelBinarizer()\n\u001B[1;32m-> 1140\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_label_binarizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label_binarizer\u001B[38;5;241m.\u001B[39mclasses_\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\HousingProject\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302\u001B[0m, in \u001B[0;36mLabelBinarizer.fit\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my has 0 samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m y)\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparse_input_ \u001B[38;5;241m=\u001B[39m sp\u001B[38;5;241m.\u001B[39missparse(y)\n\u001B[1;32m--> 302\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m \u001B[43munique_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\HousingProject\\lib\\site-packages\\sklearn\\utils\\multiclass.py:103\u001B[0m, in \u001B[0;36munique_labels\u001B[1;34m(*ys)\u001B[0m\n\u001B[0;32m    101\u001B[0m _unique_labels \u001B[38;5;241m=\u001B[39m _FN_UNIQUE_LABELS\u001B[38;5;241m.\u001B[39mget(label_type, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _unique_labels:\n\u001B[1;32m--> 103\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown label type: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mrepr\u001B[39m(ys))\n\u001B[0;32m    105\u001B[0m ys_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(chain\u001B[38;5;241m.\u001B[39mfrom_iterable(_unique_labels(y) \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m ys))\n\u001B[0;32m    107\u001B[0m \u001B[38;5;66;03m# Check that we don't mix string type with number type\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Unknown label type: (array([12.24769912, 12.10901644, 12.31717117, ..., 12.49313327,\n       11.86446927, 11.90159023]),)"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(x_scaled, np.ravel(y))\n",
    "#scores = cross_val_score(clf, x_scaled, np.ravel(y), cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "#print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "#scores_map['MLPClassifier'] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\.conda\\envs\\HousingProject\\lib\\site-packages\\seaborn\\categorical.py:470: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "scores_map = pd.DataFrame(scores_map)\n",
    "sns.boxplot(data=scores_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
